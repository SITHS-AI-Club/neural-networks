{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep & Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install keras==2.3.1\n",
    "# version prerequisite before we start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# These python libraries are standard for use with deep learning. Think of bringing a toolbox with a\n",
    "# bunch of useful functions when you call 'import'. We rename each into `np` and `pd` to save time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we'll download a dataset of images that we can use for training. They are a compilation of handwritten digits, called MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist \n",
    "# importing the dataset library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
    "# downloading the dataset. We also split the data into `train` and `test`, remember this for later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use the `x_train` and `y_train` to make the model learn/'train' (obviously) on handwritten digits. \n",
    "### Then, we test how good the model is using `x_test` and `y_test`, which are handwritten image data that it had _never_ seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "# This library can be used to visualize the kind of data we just downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,10,figsize=(20,20))\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.label_outer()\n",
    "    ax.imshow(x_train[i])\n",
    "    ax.set_title(f'Label: {y_train[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^^ These are 10 pics of different numbers, with (hopefully) correct labels corresponding it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "# we need to reformat some of the labels into a more usable form for later. This is called one-hot encoding (google it if you like)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold up, whats Deep Learning again?\n",
    "![DNN illustration](https://ml4a.github.io/images/figures/mnist_1layer.png)\n",
    "### Deep Learning gets computers to do certain things that humans could do really well (e.g. identifing digits) by modeling a simple brain with mathematical neurons/nodes, represented as lines and circles as seen above.\n",
    "### Using this, we can train a model that can very accurately determine digits on an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras is a toolbox of functions just like `numpy` and `pandas`, which is instead specialized for dealing with Artificial Intelligence and Deep Learning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# we will be importting certain functions individually later, but its safe to have the whole library than to be sorry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras is based off of the TensorFlow deep learning library, which is developed by Google. Keras is one of the _easiest_ libraries to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.backend.image_data_format()) \n",
    "# this is a sanity check, please run and make sure it outputs 'channels_last'. Let us know if it doesn't (low chances of it happening anyways)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "# allows us to 'build' our deep learning models for prediction\n",
    "from keras.layers import Dense, Activation, Flatten \n",
    "# Some building blocks for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "# initializing a new model to be made with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten()) # Turn image into a list of numbers to crunch up \n",
    "model.add(Dense(16, activation='relu', input_shape=(28*28,))) # input_shape = the dimensions of our image, which is 28 x 28\n",
    "model.add(Dense(32, activation='relu')) \n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# activation functions => Imagine this kinda like thresholds and action potentials of brain neurons.\n",
    "\n",
    "# 'relu' is an extremely popular and efficient choice for layers before your last\n",
    "# 'sigmoid' is chosen if your last layer only has one output node, 'softmax' if multiple nodes\n",
    "\n",
    "# More info: https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# loss: tells us how far the model is from the 'correct' answer (label). Is basically the model's 'report card' of how well it's doing\n",
    "# 'categorical_crossentropy' is a robust choice for a loss function when classifiying multiple classes (digits from 0 to 9)\n",
    "\n",
    "# optimizer: necessary for the model to learn from loss and improve over time as it trains.\n",
    "# 'adam' is a very efficient optimizer, now used on some of the best deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below, we are 'training' the model by giving it lots of data from `x_train` and `y_train`\n",
    "### You'll start to see progress bars as the model crunches millions of numbers and learn how to tell apart different numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    batch_size=128, \n",
    "                    epochs=10) \n",
    "\n",
    "# batch size: how many images do you want the model to 'look' at before tweaking itself?\n",
    "# epochs: how many times do you want the model to work through all the images you gave?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also see how loss and accuracy changes over time (for the better in this case)\n",
    "### We get and plot the information from `history`, which is defined when we were training the model right before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "axs[0].plot(history.history['loss'])\n",
    "axs[0].set_title('Loss')\n",
    "axs[1].plot(history.history['accuracy'])\n",
    "axs[1].set_title('Training Accuracy')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for the great reveal: __testing our model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test) \n",
    "# we use x_test and y_test to see if our model lives up to its purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Testing Accuracy: {round(score[1]*100,4)}%')\n",
    "print(f'Testing Loss: {round(score[0],4)}')\n",
    "# print our test scores (Accuracy and Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usually, it is normal if testing metrics are overall worse than training; after all, the model never saw any of the test data. However, we can still improve this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs): specialized for image data, like the MNIST handwritten digit dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN animation](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The bottom (blue) is the original image, and the top (cyan) represents the output of the convolution layer. All of this operates on a _kernel_ , which you see is the 3 x 3 pixel shadow on the bottom transformed into one pixel at the top.\n",
    "\n",
    "### Convolution layers can have many kernels in a CNN. Kernels look for specific patterns they're assigned with and trace all over the input. They output a very high value if they come across patterns on the input that matches theirs well ... and vice versa.\n",
    "\n",
    "### All of this helps to extract only the most important features on the input (image) that determines it's classification (in our case, its the core features that classify which number it is)\n",
    "\n",
    "### Look below for a visualization of CNN's up close (or [here](https://youtu.be/f0t-OCG79-U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/f0t-OCG79-U\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/f0t-OCG79-U\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Making a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "# we import certain keras-specific functions that let us build CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# We are preprocessing input data... \n",
    "# Convolution layers (Conv2D) expect a 3rd layer of RGB color, but MNIST is only single-color channeled (black-white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = Sequential()\n",
    "# start another model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.add(Conv2D(16, kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
    "model_cnn.add(Conv2D(32, kernel_size=(3,3),activation='relu'))\n",
    "model_cnn.add(MaxPooling2D()) \n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128, activation='relu'))\n",
    "model_cnn.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# kernel_size: pretty self-explanatory (how big your kernel is, in terms of pixels)\n",
    "# MaxPooling2D is similar to convolution layers, but instead they filter only the highest-valued pixel out of a small region. \n",
    "# This helps to decrease computational load, while making it easier to generalize on slightly different data (in this case, different handwriting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_cnn = model_cnn.fit(x_train,\n",
    "                            y_train,\n",
    "                            batch_size=128,\n",
    "                            epochs=5) \n",
    "# using less epochs since CNN's are more computation-heavy and take more time for each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can see how each epoch takes longer to complete. A CNN requires much more computing power and will need to train for a long time, unless you have a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_cnn.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Testing Accuracy: {round(score[1]*100,4)}%')\n",
    "print(f'Testing Loss: {round(score[0],4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If done correctly, our score with the CNN should be higher than our previous model. Rerun cells from `model_cnn = Sequential()` if you get an oddly low score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __*CHALLENGE*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "# Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You are given a dataset called Fashion_MNIST, a collection of images of different types of clothing (pants, shirts, shoes, etc.) \n",
    "### __Make a CNN that can tell apart between these different images, just like the previous examples__\n",
    "### You have reference to all resources in this notebook, as well as the [keras documentation](https://keras.io/). <sub><sup>(hint: some code that makes the CNN for this dataset is avaliable there!)</sup></sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - your turn..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
